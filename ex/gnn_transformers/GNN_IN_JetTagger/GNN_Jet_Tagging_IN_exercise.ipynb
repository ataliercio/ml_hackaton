{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4875b4e-9b1a-4d31-b8cf-13706e17085c",
   "metadata": {},
   "source": [
    "In this notebook, we perform a Jet identification task using a graph-based multiclass classifier with INs.\n",
    "\n",
    "The problem consists in identifying a given jet as a quark, a gluon, a W, a Z, or a top, based on a jet image, i.e., a 2D histogram of the transverse momentum (pt) deposited in each of 100x100 bins of a square window of the (η, ϕ) plane, centered along the jet axis.\n",
    "\n",
    "For details on the physics problem, see https://arxiv.org/pdf/1804.06913.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "355acf10-cd52-4308-83a8-316e06b6491a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8228a182-ec2d-45bb-9cf5-da7367f39293",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd.variable import *\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99348859-9714-4180-a794-f4888b1ecb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7683d8-4057-44c1-ba32-dfb59d6393b8",
   "metadata": {},
   "source": [
    "## Preparation of the training and validation samples\n",
    "\n",
    "In order to import the dataset, we now clone the dataset repository (to import the data in Colab)\n",
    "\n",
    "* load the h5 files in the data/ repository\n",
    "* extract the data we need: a target and jetImage\n",
    "* To type shell commands, we start the command line with !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d26954b-f111-402d-af34-6ef361731676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'tutorials'...\n",
      "remote: Enumerating objects: 690, done.\u001b[K\n",
      "remote: Counting objects: 100% (111/111), done.\u001b[K\n",
      "remote: Compressing objects: 100% (76/76), done.\u001b[K\n",
      "remote: Total 690 (delta 51), reused 92 (delta 32), pack-reused 579\u001b[K\n",
      "Receiving objects: 100% (690/690), 565.84 MiB | 28.33 MiB/s, done.\n",
      "Resolving deltas: 100% (253/253), done.\n",
      "Updating files: 100% (75/75), done.\n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/pierinim/tutorials.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47d70987-354c-474d-8338-17ac8dcd7631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jetImage_7_100p_0_10000.h5\tjetImage_7_100p_50000_60000.h5\n",
      "jetImage_7_100p_10000_20000.h5\tjetImage_7_100p_60000_70000.h5\n",
      "jetImage_7_100p_30000_40000.h5\tjetImage_7_100p_70000_80000.h5\n",
      "jetImage_7_100p_40000_50000.h5\tjetImage_7_100p_80000_90000.h5\n"
     ]
    }
   ],
   "source": [
    "! ls tutorials/Data/JetDataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "613ba53c-585c-478d-884c-a62a3b20ae2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending tutorials/Data/JetDataset/jetImage_7_100p_30000_40000.h5\n",
      "Appending tutorials/Data/JetDataset/jetImage_7_100p_60000_70000.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_237/661224073.py:13: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  f = h5py.File(fileIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending tutorials/Data/JetDataset/jetImage_7_100p_50000_60000.h5\n",
      "Appending tutorials/Data/JetDataset/jetImage_7_100p_10000_20000.h5\n",
      "Appending tutorials/Data/JetDataset/jetImage_7_100p_0_10000.h5\n",
      "(50000, 5) (50000, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "target = np.array([])\n",
    "jetList = np.array([])\n",
    "# we cannot load all data on Colab. So we just take a few files\n",
    "datafiles = ['tutorials/Data/JetDataset/jetImage_7_100p_30000_40000.h5',\n",
    "           'tutorials/Data/JetDataset/jetImage_7_100p_60000_70000.h5',\n",
    "            'tutorials/Data/JetDataset/jetImage_7_100p_50000_60000.h5',\n",
    "            'tutorials/Data/JetDataset/jetImage_7_100p_10000_20000.h5',\n",
    "            'tutorials/Data/JetDataset/jetImage_7_100p_0_10000.h5']\n",
    "# if you are running locallt, you can use the full dataset doing\n",
    "# for fileIN in glob.glob(\"tutorials/HiggsSchool/data/*h5\"):\n",
    "for fileIN in datafiles:\n",
    "    print(\"Appending %s\" %fileIN)\n",
    "    f = h5py.File(fileIN)\n",
    "    # for pT, eta, phi\n",
    "    myJetList = np.array(f.get(\"jetConstituentList\")[:,:,[5,8,11]])\n",
    "    # for px, py, pz\n",
    "    #myJetList = np.array(f.get(\"jetConstituentList\")[:,:,[0,1,2]])\n",
    "    mytarget = np.array(f.get('jets')[0:,-6:-1])\n",
    "    jetList = np.concatenate([jetList, myJetList], axis=0) if jetList.size else myJetList\n",
    "    target = np.concatenate([target, mytarget], axis=0) if target.size else mytarget\n",
    "    del myJetList, mytarget\n",
    "    f.close()\n",
    "print(target.shape, jetList.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1cd76b7-dc56-47f6-9981-78cbdd158ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch Cross Entropy doesn't support one-hot encoding\n",
    "target = np.argmax(target, axis=1)\n",
    "# the dataset is N_jets x N_particles x N_features\n",
    "# the IN wants N_jets x N_features x N_particles\n",
    "jetList = np.swapaxes(jetList, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5b94080-668d-4438-bf21-8d549abc6733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3, 30)\n"
     ]
    }
   ],
   "source": [
    "nParticle = 30\n",
    "jetList = jetList[:,:,:nParticle]\n",
    "print(jetList.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60253069-c615-4398-b449-58dfb325f449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33500, 3, 30) (16500, 3, 30) (33500,) (16500,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(jetList, target, test_size=0.33)\n",
    "print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)\n",
    "del jetList, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bac9c74-5ebc-4638-ad47-c279afe2e509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if a GPU is available. Otherwise run on CPU\n",
    "device = 'cpu'\n",
    "args_cuda = torch.cuda.is_available()\n",
    "if args_cuda: device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6059e3ef-88e6-4ad3-b63d-4cd59f9cdcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dataset to pytorch\n",
    "X_train = Variable(torch.FloatTensor(X_train)).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03432d74-5d79-4085-9825-827f252eea58",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9baa4168-a1f3-42b6-b459-853e7c286a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "class GraphNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GraphNet, self).__init__()\n",
    "        \n",
    "        self.P = 3 # number of features\n",
    "        self.N = nParticle # number of particles\n",
    "        self.Nr = self.N * (self.N - 1)\n",
    "        self.De = 8 # dimensionality of De learned representation\n",
    "        self.Do = 8 # number of engineered features\n",
    "        self.n_targets = 5 # number of target classes\n",
    "        self.assign_matrices() # build Rr and Rs\n",
    "        \n",
    "        self.batchnorm_x = nn.BatchNorm1d(self.P)\n",
    "        # a dense layer is allocated doing\n",
    "        # layer = nn.Linear(nodes_in, nodes_out).to(device)\n",
    "        # This computes y = w*x + b\n",
    "        # activation functions come later \n",
    "        self.fr1 =  # FILL THIS LINE making sure that the input dimension is correct\n",
    "        self.fr2 =  # FILL THIS LINE\n",
    "        self.fr3 =  # FILL THIS LINE making sure that the output dimension is correct\n",
    "        \n",
    "        self.fo1 = # FILL THIS LINE making sure that the input dimension is correct\n",
    "        self.fo2 = # FILL THIS LINE\n",
    "        self.fo3 = # FILL THIS LINE making sure that the output dimension is correct\n",
    "        \n",
    "        self.fc1 = # FILL THIS LINE making sure that the input dimension is correct\n",
    "        self.fc2 = # FILL THIS LINE\n",
    "        self.fc3 = # FILL THIS LINE making sure that the output dimension is correct\n",
    "             \n",
    "    def assign_matrices(self):\n",
    "        self.Rr = torch.zeros(self.N, self.Nr)\n",
    "        self.Rs = torch.zeros(self.N, self.Nr)\n",
    "        receiver_sender_list = [i for i in itertools.product(range(self.N), range(self.N)) if i[0]!=i[1]]\n",
    "        for i, (r, s) in enumerate(receiver_sender_list):\n",
    "            self.Rr[r, i] = 1\n",
    "            self.Rs[s, i] = 1\n",
    "        self.Rr = Variable(self.Rr).to(device)\n",
    "        self.Rs = Variable(self.Rs).to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # normalize inputs so that mean=0 and rms=1 [it helps training]\n",
    "        x = self.batchnorm_x(x) # [batch, P, N]\n",
    "        # use Rr and Rs to create the B matrix\n",
    "        Orr = self.tmul(x, self.Rr)\n",
    "        Ors = self.tmul(x, self.Rs)\n",
    "        # This is how you append two tensors\n",
    "        # the 1 means that Rs is appended to Rr along the the second - vertical - axis \n",
    "        B = torch.cat([Orr, Ors], 1)\n",
    "        \n",
    "        ### First MLP ###\n",
    "        # this is how you transpose \n",
    "        # we transpose a lot. This is because we represent the input such\n",
    "        # that each column is an interation (or a message) between a sender and a receiver\n",
    "        # We want to pass *columns* to the dense NNs\n",
    "        B = torch.transpose(B, 1, 2).contiguous()\n",
    "        # the view command is a reshape function\n",
    "        B = nn.functional.relu(self.fr1(B.view(-1, 2 * self.P)))\n",
    "        B = # FILL THIS LINE\n",
    "        E = nn.functional.relu(self.fr3(B).view(-1, self.Nr, self.De))\n",
    "        del B\n",
    "        # now we transpose E back, so that interation are columns\n",
    "        E = torch.transpose(E, 1, 2).contiguous()\n",
    "        Ebar = self.tmul(E, torch.transpose(self.Rr, 0, 1).contiguous())\n",
    "        del E\n",
    "        # we build C appending Ebar to x \n",
    "        C = # FILL THIS LINE\n",
    "        del Ebar\n",
    "        # again, we want to pass columns to the next networks.\n",
    "        # so we transpose\n",
    "        C = # FILL THIS LINE\n",
    "        ### Second MLP ###\n",
    "        C = nn.functional.relu(self.fo1(C.view(-1, self.P + self.De)))\n",
    "        C = # FILL THIS LINE\n",
    "        O = nn.functional.relu(self.fo3(C).view(-1, self.N, self.Do))\n",
    "        del C\n",
    "        # to build features, we apply an aggregation function \n",
    "        # you can use .sum, .max, etc (see https://pytorch.org/docs/stable/torch.html)\n",
    "        # the operation goes on the second axis, so you want to do torch.SOMETHING(O, 1)\n",
    "        O = torch.sum(O,1)\n",
    "        ### Classification MLP ###\n",
    "        N = # FILL THIS LINE\n",
    "        N = # FILL THIS LINE\n",
    "        del O\n",
    "        N = # FILL THIS LINE: remember that the loss function in pytorch applies the softmax function\n",
    "        return N\n",
    "\n",
    "    def tmul(self, x, y):  #Takes (I * J * K)(K * L) -> I * J * L \n",
    "        x_shape = x.size()\n",
    "        y_shape = y.size()\n",
    "        prod = torch.mm(x.reshape(x_shape[0]*x_shape[1], x_shape[2]), y).view(-1, x_shape[1], y_shape[1])\n",
    "        return prod\n",
    "\n",
    "def get_sample(training, target, choice):\n",
    "    target_vals = np.argmax(target, axis = 1)\n",
    "    ind, = np.where(target_vals == choice)\n",
    "    chosen_ind = np.random.choice(ind, 50000)\n",
    "    return training[chosen_ind], target[chosen_ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fec2a7d-4db6-420f-a464-6a24263f5025",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a31b7882-8f02-4ea2-8ecd-7b4aa345d7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "batch_size = 100\n",
    "#needed for EarlyStopping\n",
    "patience =  10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89361d7-f9b8-4833-b738-a32ff2be0978",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn = GraphNet()\n",
    "gnn.to(device)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(gnn.parameters(), lr = 0.0001)\n",
    "\n",
    "loss_train = np.zeros(n_epochs)\n",
    "acc_train = np.zeros(n_epochs)\n",
    "loss_val = np.zeros(n_epochs)\n",
    "acc_val = np.zeros(n_epochs)\n",
    "for i in range(n_epochs):\n",
    "    print(\"Epoch %s\" % i)\n",
    "    for j in range(0, X_train.size()[0], batch_size):\n",
    "        optimizer.zero_grad()\n",
    "        out = gnn(X_train[j:j + batch_size,:,:])\n",
    "        target = y_train[j:j + batch_size]\n",
    "        l = loss(out, target)\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        loss_train[i] += l.cpu().data.numpy()*batch_size\n",
    "    loss_train[i] = loss_train[i]/X_train.shape[0]\n",
    "    #acc_train[i] = stats(predicted, Y_val)\n",
    "    #### val loss & accuracy\n",
    "    for j in range(0, X_val.size()[0], batch_size):\n",
    "        out_val = gnn(X_val[j:j + batch_size])\n",
    "        target_val =  y_val[j:j + batch_size]\n",
    "        \n",
    "        l_val = loss(out_val,target_val)\n",
    "        loss_val[i] += l_val.cpu().data.numpy()*batch_size\n",
    "    loss_val[i] = loss_val[i]/X_val.shape[0]\n",
    "    print(\"Training   Loss: %f\" %l.cpu().data.numpy())\n",
    "    print(\"Validation Loss: %f\" %l_val.cpu().data.numpy())\n",
    "    if all(loss_val[max(0, i - patience):i] > min(np.append(loss_val[0:max(0, i - patience)], 200))) and i > patience:\n",
    "        print(\"Early Stopping\")\n",
    "        break\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e18b562e-d0d8-4261-9ddb-628379ae533a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e471bac3-389c-4b7c-830e-2d06e6beed5f",
   "metadata": {},
   "source": [
    "## Building the ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d982a08-a02b-4500-b253-d545b4df3251",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build ROC"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
